{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d3ae7c-3587-4f95-bf8a-bca540e3e8d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "This is a script that performs all the pre-processing necessary for the all-sky source search and source class search of neutrino flux from IceCube's muon track data. The majority of the pre-processing is simply moving fixed width text files to numpy pickle files for quicker reading. The more time consuming pre-processing performed is the background PDF calculation and the integration of IceCube's detector effective area over energy and a neutrino flux. \n",
    "\n",
    "First, I load the IceCube track data into a pickle file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007f40cc-4383-4fcb-b68e-56f328a18168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filename: ./data/3year-data-release/IC86-2012-events.txt\n",
      "Loading filename: ./data/3year-data-release/IC79-2010-events.txt\n",
      "Loading filename: ./data/3year-data-release/IC86-2011-events.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import A01_open_and_convert_icecube_data\n",
    "    \n",
    "raw_icecube_file_names = glob.glob(\"./data/3year-data-release/IC*-events.txt\")\n",
    "output_file_name = \"processed_data/output_icecube_data.npz\"\n",
    "A01_open_and_convert_icecube_data.main(raw_icecube_file_names, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c79b9e-170b-4845-866d-3c8c03d2ec4e",
   "metadata": {},
   "source": [
    "Next, I calculate the background PDF back scrambling the IceCube track data in RA in $\\pm3^\\circ$ bands in declination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff54e624-411a-45f6-9ed5-54e9dee78b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsmith/Documents/icecube/2022_04_04_icecube_source_analysis/3yr_icecube_source_search/A02_analyze_background.py:58: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  sweep_counts_norm, err = scipy.integrate.quad(f_integrand,\n"
     ]
    }
   ],
   "source": [
    "import A02_analyze_background\n",
    "\n",
    "icecube_file_name = output_file_name\n",
    "output_file_name = \"processed_data/output_icecube_background_count.npz\"\n",
    "sweep_dec, B_i = A02_analyze_background.main(icecube_file_name, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae76769-5511-4c93-9e8e-95bd901cd067",
   "metadata": {},
   "source": [
    "The next block simply loads the 4LAC catalog FITS file and saves it to a numpy pickle file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9321838-b68b-462f-b978-3cfbbf4e627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import A04p1_open_and_convert_4LAC_catalog\n",
    "\n",
    "fits_file_name = \"./data/table_4LAC.fits\"\n",
    "output_file_name = \"./processed_data/4LAC_catelogy.npz\"\n",
    "A04p1_open_and_convert_4LAC_catalog.open_and_convert_catalog(fits_file_name, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba7a4c-d5a9-4b7c-80a8-28b7588ae4bc",
   "metadata": {},
   "source": [
    "The next block is by far the most time consuming (~1 min), and loads IceCube's detector effective volume, averages for detector type (number of strings used for that given year of deployment), and integrates over the following:\n",
    "\n",
    "$$\n",
    "A'_{eff}(\\delta) = \\int_{E_{min}}^{E_{max}} E'^{-\\alpha} A_{eff}(E', \\delta) dE'\n",
    "$$\n",
    "\n",
    "Ultimately, this is will be used to calculate the number of neutrino from a source, $N_\\nu$, from a source class using the integral,\n",
    "\n",
    "$$ \n",
    "N_\\nu = \\int dt \\int d\\Omega \\int_0^\\infty dE' A_{eff}(E', \\delta) \\phi_\\nu(E_\\nu, \\Omega, t).\n",
    "$$\n",
    "\n",
    "More description of the process is available both in the paper and in the `README.md` of the GitHub repository.\n",
    "\n",
    "Two different spectral indices are computed, $\\alpha=2.0$ and $2.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ff1f20-05e4-42f2-99b8-3265cfa95d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsmith/Documents/icecube/2022_04_04_icecube_source_analysis/3yr_icecube_source_search/A04p2_open_and_convert_icecube_Aeff.py:77: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  integrated_Aeff, int_Aeff_error = scipy.integrate.quad(f_integrand,\n",
      "/Users/danielsmith/Documents/icecube/2022_04_04_icecube_source_analysis/3yr_icecube_source_search/A04p2_open_and_convert_icecube_Aeff.py:77: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  integrated_Aeff, int_Aeff_error = scipy.integrate.quad(f_integrand,\n",
      "/Users/danielsmith/Documents/icecube/2022_04_04_icecube_source_analysis/3yr_icecube_source_search/A04p2_open_and_convert_icecube_Aeff.py:77: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  integrated_Aeff, int_Aeff_error = scipy.integrate.quad(f_integrand,\n",
      "/Users/danielsmith/Documents/icecube/2022_04_04_icecube_source_analysis/3yr_icecube_source_search/A04p2_open_and_convert_icecube_Aeff.py:77: IntegrationWarning: The algorithm does not converge.  Roundoff error is detected\n",
      "  in the extrapolation table.  It is assumed that the requested tolerance\n",
      "  cannot be achieved, and that the returned result (if full_output = 1) is \n",
      "  the best which can be obtained.\n",
      "  integrated_Aeff, int_Aeff_error = scipy.integrate.quad(f_integrand,\n"
     ]
    }
   ],
   "source": [
    "import A04p2_open_and_convert_icecube_Aeff\n",
    "\n",
    "input_file_names = glob.glob(\"./data/3year-data-release/*Aeff.txt\")\n",
    "\n",
    "for alpha in [2.0, 2.5]:\n",
    "    output_file_name = \"./processed_data/output_icecube_AffIntegrated_%s.npz\" % alpha\n",
    "    dec_steps, y_integrate_steps = A04p2_open_and_convert_icecube_Aeff.load_Aeff(input_file_names, output_file_name, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
